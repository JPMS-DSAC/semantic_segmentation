{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of LSTMwithATTN_Trial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1aZCyYJi0Y9KLLpQ77F3LnoxwYKRB1oyn",
      "authorship_tag": "ABX9TyPiAto/6NrDJpXKtoJpsfKw"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCsEqIK0Wy8p"
      },
      "source": [
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from sklearn.utils import shuffle\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "import os\n",
        "from torchtext.vocab import Vectors, GloVe\n",
        "import time\n",
        "import torch.optim as optim\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KrM1-YbGC0K"
      },
      "source": [
        "class SelfAttention(nn.Module):\n",
        "\tdef __init__(self, batch_size, output_size, hidden_size, vocab_size, embedding_length, weights):\n",
        "\t\tsuper(SelfAttention, self).__init__()\n",
        "\n",
        "\t\tself.batch_size = batch_size\n",
        "\t\tself.output_size = output_size\n",
        "\t\tself.hidden_size = hidden_size\n",
        "\t\tself.vocab_size = vocab_size\n",
        "\t\tself.embedding_length = embedding_length\n",
        "\t\tself.weights = weights\n",
        "\n",
        "\t\tself.word_embeddings = nn.Embedding(vocab_size, embedding_length)\n",
        "\t\tself.word_embeddings.weights = nn.Parameter(weights, requires_grad=False)\n",
        "\t\tself.dropout = 0.8\n",
        "\t\tself.bilstm = nn.LSTM(embedding_length, hidden_size, dropout=self.dropout, bidirectional=True)\n",
        "\t\t# We will use da = 350, r = 30 & penalization_coeff = 1 as per given in the self-attention original ICLR paper\n",
        "\t\tself.W_s1 = nn.Linear(2*hidden_size, 350)\n",
        "\t\tself.W_s2 = nn.Linear(350, 30)\n",
        "\t\tself.fc_layer = nn.Linear(30*2*hidden_size, 2000)\n",
        "\t\tself.label = nn.Linear(2000, 10)\n",
        "\n",
        "\tdef attention_net(self, lstm_output):\n",
        "\n",
        "\t\tattn_weight_matrix = self.W_s2(torch.tanh(self.W_s1(lstm_output)))\n",
        "\t\tattn_weight_matrix = attn_weight_matrix.permute(0, 2, 1)\n",
        "\t\tattn_weight_matrix = F.softmax(attn_weight_matrix, dim=2)\n",
        "\n",
        "\t\treturn attn_weight_matrix\n",
        "\n",
        "\tdef forward(self, input_sentences, batch_size=None):\n",
        "\n",
        "\t\tinput = self.word_embeddings(input_sentences)\n",
        "\t\tinput = input.permute(1, 0, 2)\n",
        "\t\tif batch_size is None:\n",
        "\t\t\th_0 = Variable(torch.zeros(2, self.batch_size, self.hidden_size))\n",
        "\t\t\tc_0 = Variable(torch.zeros(2, self.batch_size, self.hidden_size))\n",
        "\t\telse:\n",
        "\t\t\th_0 = Variable(torch.zeros(2, batch_size, self.hidden_size))\n",
        "\t\t\tc_0 = Variable(torch.zeros(2, batch_size, self.hidden_size))\n",
        "\n",
        "\t\toutput, (h_n, c_n) = self.bilstm(input, (h_0, c_0))\n",
        "\t\toutput = output.permute(1, 0, 2)\n",
        "\t\tattn_weight_matrix = self.attention_net(output)\n",
        "\t\thidden_matrix = torch.bmm(attn_weight_matrix, output)\n",
        "\t\tfc_out = self.fc_layer(hidden_matrix.view(-1, hidden_matrix.size()[1]*hidden_matrix.size()[2]))\n",
        "\t\tlogits = self.label(fc_out)\n",
        "\n",
        "\t\treturn logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE0N52ecWzug"
      },
      "source": [
        "\n",
        "\n",
        "def load_dataset(data_path='/content/drive/MyDrive/SEBI /Adjudication Orders Annotations JSON/Model Data CSV/'):\n",
        "\n",
        "    LABEL = data.LabelField(lower=True)\n",
        "    TEXT =  data.Field(sequential=True,tokenize='spacy',lower=False, batch_first=True,fix_length=300)\n",
        "    fields  = [(None,None),(None,None),('Label',LABEL),('text',TEXT)]\n",
        "    \n",
        "    train_ds,test_ds = data.TabularDataset.splits(\n",
        "      path = data_path,\n",
        "      train = 'model3_train_4.csv',\n",
        "      test = 'test_4.csv',\n",
        "      format = 'csv',\n",
        "      fields = fields,\n",
        "      skip_header = True)\n",
        "    \n",
        "    TEXT.build_vocab(train_ds, vectors=GloVe(name='6B', dim=300))\n",
        "    LABEL.build_vocab(train_ds)\n",
        "\n",
        "    word_embeddings = TEXT.vocab.vectors\n",
        "    print (\"Length of Text Vocabulary: \" + str(len(TEXT.vocab)))\n",
        "    print (\"Vector size of Text Vocabulary: \", TEXT.vocab.vectors.size())\n",
        "    print (\"Label Length: \" + str(len(LABEL.vocab)))\n",
        "\n",
        "\n",
        "    train_data, valid_data = train_ds.split() # Further splitting of training_data to create new training_data & validation_data\n",
        "    train_iter, valid_iter, test_iter = data.BucketIterator.splits((train_data, valid_data, test_ds), batch_size=32,  sort_key=lambda x: len(x.text), repeat=False, shuffle=True)\n",
        "\n",
        "    vocab_size = len(TEXT.vocab)\n",
        "    label_vocab = LABEL.vocab\n",
        "\n",
        "    return TEXT, vocab_size, word_embeddings, train_iter, valid_iter, test_iter, label_vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exrd8RKKUBDG"
      },
      "source": [
        "TEXT, vocab_size, word_embeddings, train_iter, valid_iter, test_iter, label_vocab = load_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_Fn9ZCzagPu"
      },
      "source": [
        "index_vocab = label_vocab.stoi\n",
        "index_vocab\n",
        "\n",
        "index_list = label_vocab.itos\n",
        "index_list "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnh1XCjAJWfI"
      },
      "source": [
        "\n",
        "def clip_gradient(model, clip_value):\n",
        "    params = list(filter(lambda p: p.grad is not None, model.parameters()))\n",
        "    for p in params:\n",
        "        p.grad.data.clamp_(-clip_value, clip_value)\n",
        "    \n",
        "def train_model(model, train_iter, epoch):\n",
        "    total_epoch_loss = 0\n",
        "    total_epoch_acc = 0\n",
        "    optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "    steps = 0\n",
        "    model.train()\n",
        "    for idx, batch in enumerate(train_iter):\n",
        "        text = batch.text\n",
        "        target = batch.Label\n",
        "        target = torch.autograd.Variable(target).long()\n",
        "        if (text.size()[0] is not 32):# One of the batch returned by BucketIterator has length different than 32.\n",
        "            continue\n",
        "        optim.zero_grad()\n",
        "        prediction = model(text)\n",
        "        loss = loss_fn(prediction, target)\n",
        "        num_corrects = (torch.max(prediction, 1)[1].view(target.size()).data == target.data).float().sum()\n",
        "        acc = 100.0 * num_corrects/len(batch)\n",
        "        loss.backward()\n",
        "        clip_gradient(model, 1e-1)\n",
        "        optim.step()\n",
        "        steps += 1\n",
        "        \n",
        "        if steps % 100 == 0:\n",
        "            print (f'Epoch: {epoch+1}, Idx: {idx+1}, Training Loss: {loss.item():.4f}, Training Accuracy: {acc.item(): .2f}%')\n",
        "        \n",
        "        total_epoch_loss += loss.item()\n",
        "        total_epoch_acc += acc.item()\n",
        "        \n",
        "    return total_epoch_loss/len(train_iter), total_epoch_acc/len(train_iter)\n",
        "\n",
        "def eval_model(model, val_iter):\n",
        "    total_epoch_loss = 0\n",
        "    total_epoch_acc = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(val_iter):\n",
        "            text = batch.text\n",
        "            if (text.size()[0] is not 32):\n",
        "                continue\n",
        "            target = batch.Label\n",
        "            target = torch.autograd.Variable(target).long()\n",
        "            prediction = model(text)\n",
        "            #print(target,torch.max(prediction, 1)[1].view(target.size()).data,sep='\\n\\n')\n",
        "            loss = loss_fn(prediction, target)\n",
        "            num_corrects = (torch.max(prediction, 1)[1].view(target.size()).data == target.data).sum()\n",
        "            acc = 100.0 * num_corrects/len(batch)\n",
        "            total_epoch_loss += loss.item()\n",
        "            total_epoch_acc += acc.item()\n",
        "\n",
        "    return total_epoch_loss/len(val_iter), total_epoch_acc/len(val_iter)\n",
        "\t\n",
        "\n",
        "learning_rate = 0.001\n",
        "batch_size = 32\n",
        "output_size = 10\n",
        "hidden_size = 256\n",
        "embedding_length = 300\n",
        "\n",
        "model = SelfAttention(batch_size, output_size, hidden_size, vocab_size, embedding_length, word_embeddings)\n",
        "loss_fn = F.cross_entropy\n",
        "\n",
        "for epoch in range(11):\n",
        "    train_loss, train_acc = train_model(model, train_iter, epoch)\n",
        "    val_loss, val_acc = eval_model(model, valid_iter)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}%, Val. Loss: {val_loss:3f}, Val. Acc: {val_acc:.2f}%')\n",
        "    \n",
        "test_loss, test_acc = eval_model(model, test_iter)\n",
        "print(f'Test Loss: {test_loss:.3f}, Test Acc: {test_acc:.2f}%')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBmdVcPeUwb9"
      },
      "source": [
        "#predicitions for test data \n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "model.eval()\n",
        "all_targets = []\n",
        "all_predicted = []\n",
        "with torch.no_grad():\n",
        "    for idx, batch in enumerate(test_iter):\n",
        "        text = batch.text\n",
        "        if (text.size()[0] is not 32):\n",
        "            continue\n",
        "        target = batch.Label\n",
        "        #print(f\"taregt label {target.numpy()}\")\n",
        "        all_targets += batch.Label\n",
        "        prediction = model(text)\n",
        "        all_predicted += torch.max(prediction, 1)[1].view(target.size()).data\n",
        "        #print(f\"predicted label {torch.max(prediction, 1)[1].view(target.size()).data.numpy()}\",end='\\n\\n')\n",
        "\n",
        "\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n3GXwKAWl3T",
        "outputId": "5a695241-e15d-4229-8e16-f2867aaf78d2"
      },
      "source": [
        "print(classification_report(all_targets, all_predicted, target_names=index_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "         material fact       0.39      0.57      0.47        87\n",
            "       defendant claim       0.66      0.36      0.46        76\n",
            "       procedural fact       0.40      0.68      0.50        47\n",
            "subjective observation       0.65      0.37      0.47        41\n",
            "        statutory fact       0.40      0.43      0.41        14\n",
            "         issues framed       1.00      0.56      0.72        16\n",
            "          related fact       0.75      0.46      0.57        13\n",
            "            allegation       1.00      0.23      0.38        13\n",
            "               penalty       1.00      0.43      0.60         7\n",
            "             violation       0.10      0.17      0.12         6\n",
            "\n",
            "              accuracy                           0.48       320\n",
            "             macro avg       0.64      0.43      0.47       320\n",
            "          weighted avg       0.57      0.47      0.48       320\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}