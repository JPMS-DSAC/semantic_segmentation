{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcfOT2mwbAGC",
        "outputId": "168f6459-70d9-44ed-9672-1eb313ca645c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device details:  [name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 3820478802814075552\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 4181262336\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 3432276702511643271\n",
            "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
            "]\n",
            "\n",
            "\n",
            "Num GPUs:  1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "print(\"Device details: \",device_lib.list_local_devices(),end='\\n\\n\\n')\n",
        "print(\"Num GPUs: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cknfQJUVByC4",
        "outputId": "4c670138-e94f-433c-9c8a-c7b0aa054dad"
      },
      "outputs": [],
      "source": [
        "!pip install bert-for-tf2 \n",
        "!pip install tensorflow-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LfcCqL_nAHLc"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "#creating extra data from current files\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import bert\n",
        "from bert.tokenization.bert_tokenization import FullTokenizer\n",
        "from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights\n",
        "from bert import BertModelLayer\n",
        "\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import constraints\n",
        "\n",
        "from tensorflow.keras import activations\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras import optimizers\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorboard\n",
        "\n",
        "from tensorflow.keras.layers import Layer,Dropout, LSTM, GRU, Bidirectional, TimeDistributed, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGh3ZNKldcZi",
        "outputId": "192e1ec1-6633-412d-e7cd-c00565ba5cb6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 13069515858304671395,\n",
              " name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 4181262336\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 11529799552479874776\n",
              " physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\"]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "device_lib.list_local_devices()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTUxDN8jfTfN",
        "outputId": "242dbb3e-337b-4005-b321-d921f611bda5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mU7Cr5k4Bfqn"
      },
      "outputs": [],
      "source": [
        "############################### path check (add path to data)\n",
        "root_path = ''\n",
        "list_of_files = []\n",
        "for root, dir,files in os.walk('./Annotated - CSV'):\n",
        "  root_path = root\n",
        "  list_of_files = files\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QlVEH7WHBiA9"
      },
      "outputs": [],
      "source": [
        "all_dataframes = []\n",
        "for filename in list_of_files:\n",
        "  file_path = root_path + '/' + filename\n",
        "  file_temp = pd.read_csv(file_path)\n",
        "  all_dataframes.append(file_temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "8tIDUYyxBkPC",
        "outputId": "33d26e2d-7edd-4e49-c786-9a6ff84dc3e1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence ID</th>\n",
              "      <th>Label</th>\n",
              "      <th>Sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>F1288072330011_S1</td>\n",
              "      <td>material fact</td>\n",
              "      <td>1. The shares of Genus Commu Trade Limited (he...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>F1288072330011_S2</td>\n",
              "      <td>procedural fact</td>\n",
              "      <td>SEBI conducted an investigation in respect of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>F1288072330011_S3</td>\n",
              "      <td>material fact</td>\n",
              "      <td>2. During the investigation period, the scrip ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>F1288072330011_S4</td>\n",
              "      <td>material fact</td>\n",
              "      <td>The price reached the period low (intra day) o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>F1288072330011_S5</td>\n",
              "      <td>material fact</td>\n",
              "      <td>During the said period the total traded quanti...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Sentence ID            Label  \\\n",
              "0  F1288072330011_S1    material fact   \n",
              "1  F1288072330011_S2  procedural fact   \n",
              "2  F1288072330011_S3    material fact   \n",
              "3  F1288072330011_S4    material fact   \n",
              "4  F1288072330011_S5    material fact   \n",
              "\n",
              "                                            Sentence  \n",
              "0  1. The shares of Genus Commu Trade Limited (he...  \n",
              "1  SEBI conducted an investigation in respect of ...  \n",
              "2  2. During the investigation period, the scrip ...  \n",
              "3  The price reached the period low (intra day) o...  \n",
              "4  During the said period the total traded quanti...  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_dataframes[0].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m22xDZDSHP9M",
        "outputId": "f33e9310-b6df-42ab-f2b1-fdf7aba24fa7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#total of 29 files\n",
        "len(all_dataframes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OMr-Oas2cnle"
      },
      "outputs": [],
      "source": [
        "for df in all_dataframes:\n",
        "  context = [sent for sent in df['Sentence']]\n",
        "  df['context'] = df['Sentence'].apply(lambda x:context)\n",
        "  df['left'] = df['Sentence'].apply(lambda x:context)\n",
        "  df['right'] = df['Sentence'].apply(lambda x:context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qVWX51sfBoT7"
      },
      "outputs": [],
      "source": [
        "# combine all file dataframes into one main dataframe \n",
        "result = pd.DataFrame()\n",
        "result = result.append(all_dataframes,ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9z-SQpxAB9Ch"
      },
      "outputs": [],
      "source": [
        "# split data into 85 train and 15 test \n",
        "train_data = pd.DataFrame(columns= result.columns)\n",
        "test_data = pd.DataFrame(columns=result.columns)\n",
        "\n",
        "for label in result.Label.unique():\n",
        "  temp_df = result[result['Label'] == label]\n",
        "  train_index = int(temp_df.shape[0]*0.85)\n",
        "  train_data = train_data.append(temp_df[:train_index])\n",
        "  test_data = test_data.append(temp_df[train_index:])\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "context_size = 5\n",
        "\n",
        "for i, line in train_data.iterrows():\n",
        "    if context_size==-1:\n",
        "        break\n",
        "    ind = line['context'].index(line['Sentence'])\n",
        "    left = max(ind-context_size, 0)\n",
        "    right = min(ind+1+context_size, len(line['context']))\n",
        "    pad_left = 0\n",
        "    pad_right = 0\n",
        "    if ind-left<context_size:\n",
        "        pad_left = context_size-ind+left\n",
        "        # right+=context_size-(ind-left)\n",
        "    elif right-ind<context_size:\n",
        "        pad_right = context_size-ind+right\n",
        "        # left-=context_size-(right-ind)\n",
        "    train_data.at[i, 'left'] = line['context'][left:ind]\n",
        "    train_data.at[i, 'right'] = line['context'][ind+1:right]\n",
        "    context = line['context'][left:ind] + line['context'][ind+1:right]\n",
        "    print(left, right, len(context))\n",
        "    train_data.at[i, 'context'] = context\n",
        "\n",
        "for i, line in test_data.iterrows():\n",
        "    if context_size==-1:\n",
        "        break\n",
        "    ind = line['context'].index(line['Sentence'])\n",
        "    left = max(ind-context_size, 0)\n",
        "    right = min(ind+1+context_size, len(line['context']))\n",
        "    pad_left = 0\n",
        "    pad_right = 0\n",
        "    if ind-left<context_size:\n",
        "        pad_left = context_size-ind+left\n",
        "        # right+=context_size-(ind-left)\n",
        "    elif right-ind<context_size:\n",
        "        pad_right = context_size-ind+right\n",
        "        # left-=context_size-(right-ind)\n",
        "    test_data.at[i, 'left'] = line['context'][left:ind]\n",
        "    test_data.at[i, 'right'] = line['context'][ind+1:right]\n",
        "    context = line['context'][left:ind] + line['context'][ind+1:right]\n",
        "    print(left, right, len(context))\n",
        "    test_data.at[i, 'context'] = context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5dKRNN3MB_RO"
      },
      "outputs": [],
      "source": [
        "# remove the sentence ID column \n",
        "train_data.drop(columns = ['Sentence ID'],axis=1,inplace=True)\n",
        "test_data.drop(columns = ['Sentence ID'],axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrZEwk7uCBdZ",
        "outputId": "842fe664-b145-454a-c772-79b0dbfeeb60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "defendant claim           504\n",
              "material fact             460\n",
              "procedural fact           272\n",
              "subjective observation    241\n",
              "statutory fact            158\n",
              "issues framed              80\n",
              "related fact               73\n",
              "allegation                 69\n",
              "penalty                    35\n",
              "violation                  26\n",
              "Name: Label, dtype: int64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# distribution of data per label \n",
        "train_data['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j4QOqa-CDrL",
        "outputId": "fde8293c-2ad0-4f8b-8770-31691e93bab0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "defendant claim           90\n",
              "material fact             82\n",
              "procedural fact           49\n",
              "subjective observation    43\n",
              "statutory fact            29\n",
              "issues framed             15\n",
              "allegation                13\n",
              "related fact              13\n",
              "penalty                    7\n",
              "violation                  5\n",
              "Name: Label, dtype: int64"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test distribution of laables \n",
        "test_data['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cysDHmvECGzT",
        "outputId": "132df393-7909-485e-e375-b61a281f4727"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n",
            "\n",
            "Saved under uncased_L-12_H-768_A-12 (1).zip\n"
          ]
        }
      ],
      "source": [
        "#################### check path to download the BERT uncased version \n",
        "# get the uncased BERT model \n",
        "!pip install wget\n",
        "\n",
        "!python -m wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLwYPHybCJaB",
        "outputId": "e46d310b-0a3e-4ae2-b7c5-56a0b78a6c0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  uncased_L-12_H-768_A-12.zip\n",
            "   creating: uncased_L-12_H-768_A-12/\n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n"
          ]
        }
      ],
      "source": [
        "!unzip uncased_L-12_H-768_A-12.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ZeWT8uBnCLfd"
      },
      "outputs": [],
      "source": [
        "##################### path check \n",
        "os.makedirs(\"model\", exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQOqDmU2CQqg"
      },
      "outputs": [],
      "source": [
        "################### path check \n",
        "!mv uncased_L-12_H-768_A-12/ model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "UbW0-VYJCSZu"
      },
      "outputs": [],
      "source": [
        "bert_model_name=\"uncased_L-12_H-768_A-12\"\n",
        "############# path check \n",
        "bert_ckpt_dir = os.path.join(\"semantic_seg/model/\", bert_model_name)\n",
        "bert_ckpt_file = os.path.join(bert_ckpt_dir, \"bert_model.ckpt\")\n",
        "bert_config_file = os.path.join(bert_ckpt_dir, \"bert_config.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjrqqfFnCUWE",
        "outputId": "d0d48863-025f-4b03-8f6a-81f1f170d184"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['material fact',\n",
              " 'procedural fact',\n",
              " 'allegation',\n",
              " 'defendant claim',\n",
              " 'issues framed',\n",
              " 'statutory fact',\n",
              " 'subjective observation',\n",
              " 'violation',\n",
              " 'penalty',\n",
              " 'related fact']"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classes = train_data.Label.unique().tolist()\n",
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Ks6uiCGYCWcW"
      },
      "outputs": [],
      "source": [
        "tokenizer = FullTokenizer(vocab_file=os.path.join(bert_ckpt_dir, \"vocab.txt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "56TRGBVqCY4U"
      },
      "outputs": [],
      "source": [
        "#preprocessing\n",
        "class Data_clean:\n",
        "  #here context referes to document context\n",
        "  DATA_COLUMN = \"Sentence\"\n",
        "  LABEL_COLUMN = \"Label\"\n",
        "  LEFT_CONTEXT_COLUMN = \"left\"\n",
        "  RIGHT_CONTEXT_COLUMN = \"right\"\n",
        "  CONTEXT_COLUMN = \"Context\"\n",
        "\n",
        "  def __init__(self, train, test, tokenizer: FullTokenizer, classes, inp_seq_len, max_seq_len):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.inp_seq_len = inp_seq_len\n",
        "    self.max_seq_len = max_seq_len\n",
        "    self.max_sent_len = 0\n",
        "    self.classes = classes\n",
        "    self.dict = defaultdict(int)\n",
        "    self.sent_set = set()\n",
        "\n",
        "    train, test = map(lambda df: df.reindex(df[Data_clean.DATA_COLUMN].str.len().sort_values().index), [train, test])\n",
        "\n",
        "    print(train.count())\n",
        "    print(test.count())\n",
        "\n",
        "    ((self.train_x, self.train_x_left_context, self.train_x_right_context, self.train_y), (self.test_x, self.test_x_left_context, self.test_x_right_context, self.test_y)) = map(self._prepare, [train, test])\n",
        "\n",
        "    print(\"max seq_len\", self.max_seq_len)\n",
        "    print(\"max sent_len\", self.max_sent_len)\n",
        "    self.max_seq_len = max(self.max_seq_len, max_seq_len)\n",
        "    self.train_x, self.test_x = map(self._pad, [self.train_x, self.test_x])\n",
        "    # self.prepad_train_x_context = self.train_x_context\n",
        "    # self.prepad_test_x_context = self.test_x_context\n",
        "    print(self.train_x_left_context.size, self.train_x_right_context.size)\n",
        "    print(self.test_x_left_context.size, self.test_x_right_context.size)\n",
        "    self.train_x_left_context, self.test_x_left_context = map(self._context_pad_left, [self.train_x_left_context, self.test_x_left_context])\n",
        "    print(\"left context done\")\n",
        "    self.train_x_right_context, self.test_x_right_context = map(self._context_pad_right, [self.train_x_right_context, self.test_x_right_context])\n",
        "    print(\"right context done\")\n",
        "\n",
        "  def _prepare(self, df):\n",
        "    x, y = [], []\n",
        "    left_context_x = []\n",
        "    right_context_x = []\n",
        "    \n",
        "    for _, row in tqdm(df.iterrows()):\n",
        "      sent, left_context_text, right_context_text, label = row[Data_clean.DATA_COLUMN], row[Data_clean.LEFT_CONTEXT_COLUMN], row[Data_clean.RIGHT_CONTEXT_COLUMN], row[Data_clean.LABEL_COLUMN]\n",
        "      sent_tokens = self.tokenizer.tokenize(sent)\n",
        "      sent_tokens = [\"[CLS]\"] + sent_tokens[:self.inp_seq_len-2] + [\"[SEP]\"]\n",
        "      sent_token_ids = self.tokenizer.convert_tokens_to_ids(sent_tokens)\n",
        "      self.dict[len(sent_token_ids)]+=1\n",
        "      # self.max_seq_len = max(self.max_seq_len, len(sent_token_ids))\n",
        "      x.append(sent_token_ids)\n",
        "      #context preprocessing\n",
        "      left_row_context = []\n",
        "      for c_sent in left_context_text:\n",
        "        c_sent_tokens = self.tokenizer.tokenize(c_sent)\n",
        "        c_sent_tokens = [\"[CLS]\"] + c_sent_tokens[:self.max_seq_len-2] + [\"[SEP]\"]\n",
        "        c_sent_token_ids = self.tokenizer.convert_tokens_to_ids(c_sent_tokens)\n",
        "        \n",
        "        # self.max_seq_len = max(self.max_seq_len, len(c_sent_token_ids))\n",
        "        left_row_context.append(c_sent_token_ids)\n",
        "      \n",
        "      right_row_context = []\n",
        "      for c_sent in right_context_text:\n",
        "        c_sent_tokens = self.tokenizer.tokenize(c_sent)\n",
        "        c_sent_tokens = [\"[CLS]\"] + c_sent_tokens[:self.max_seq_len-2] + [\"[SEP]\"]\n",
        "        c_sent_token_ids = self.tokenizer.convert_tokens_to_ids(c_sent_tokens)\n",
        "        \n",
        "        # self.max_seq_len = max(self.max_seq_len, len(c_sent_token_ids))\n",
        "        right_row_context.append(c_sent_token_ids)\n",
        "\n",
        "      self.max_sent_len = max(self.max_sent_len, len(left_row_context))\n",
        "      self.max_sent_len = max(self.max_sent_len, len(right_row_context))\n",
        "      left_context_x.append(np.array(left_row_context))\n",
        "      right_context_x.append(np.array(right_row_context))\n",
        "      y.append(self.classes.index(label))\n",
        "\n",
        "    return np.array(x), np.array(left_context_x), np.array(right_context_x), np.array(y)\n",
        "\n",
        "  def _pad(self, ids):\n",
        "    x = []\n",
        "    for input_ids in ids:\n",
        "      input_ids = input_ids[:min(len(input_ids), self.inp_seq_len - 2)]\n",
        "      input_ids = input_ids + [0] * (self.inp_seq_len - len(input_ids))\n",
        "      x.append(np.array(input_ids))\n",
        "    return np.array(x)\n",
        "\n",
        "  def _context_pad_right(self, arr):\n",
        "    context_x = []\n",
        "    for row in arr:\n",
        "      row_context = []\n",
        "      for input_ids in row:\n",
        "        input_ids = input_ids[:min(len(input_ids), self.max_seq_len - 2)]\n",
        "        # input_ids = input_ids + [0] * (self.max_seq_len - len(input_ids))\n",
        "        row_context.append(np.hstack((np.array(input_ids), np.zeros(self.max_seq_len - len(input_ids)))))\n",
        "      if len(row_context) < self.max_sent_len:\n",
        "        while len(row_context) < self.max_sent_len:\n",
        "          padded_sent  = [0] * self.max_seq_len\n",
        "          row_context.append(padded_sent)\n",
        "      context_x.append(np.array(row_context))\n",
        "      # print(\"lul\")\n",
        "    return np.array(context_x)\n",
        "  \n",
        "  def _context_pad_left(self, arr):\n",
        "    context_x = []\n",
        "    for row in arr:\n",
        "      row_context = []\n",
        "      # print(row.size)\n",
        "      for input_ids in row:\n",
        "        input_ids = input_ids[:min(len(input_ids), self.max_seq_len - 2)]\n",
        "        # input_ids = input_ids + [0] * (self.max_seq_len - len(input_ids))\n",
        "        row_context.append(np.hstack((np.array(input_ids), np.zeros(self.max_seq_len - len(input_ids)))))\n",
        "      # print(len(row_context))\n",
        "      pad = []\n",
        "      if len(row_context) + len(pad) < self.max_sent_len:\n",
        "        while len(row_context) + len(pad) < self.max_sent_len:\n",
        "          padded_sent  = [0] * self.max_seq_len\n",
        "          pad.append(padded_sent)\n",
        "      # print(len(pad))\n",
        "      row_context = pad + row_context\n",
        "      context_x.append(np.array(row_context))\n",
        "      # print(\"CHAL JAJAJAJA\")\n",
        "    return np.array(context_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiiKnbpVEc9j",
        "outputId": "ac7d817f-86cd-46c4-dc0d-20642025b2b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]<ipython-input-22-916d450c21ee>:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  context_x.append(np.array(row_context))\n",
            "1918it [01:45, 18.18it/s]\n",
            "<ipython-input-22-916d450c21ee>:46: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(x), np.array(context_x),np.array(y)\n",
            "346it [00:33, 10.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max seq_len 308\n"
          ]
        }
      ],
      "source": [
        "data = Data_clean(train_data, test_data, tokenizer, classes, 300, 300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "  tf.config.experimental.set_memory_growth(gpu, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "3rX4lSU89Kas"
      },
      "outputs": [],
      "source": [
        "def dot_product(x, kernel):\n",
        "\n",
        "    if K.backend() == 'tensorflow':\n",
        "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
        "    else:\n",
        "        return K.dot(x, kernel)\n",
        "    \n",
        "\n",
        "class AttentionWithContext(Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "\n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.u_regularizer = regularizers.get(u_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.u_constraint = constraints.get(u_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        super(AttentionWithContext, self).__init__(**kwargs)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'W_regularizer' : self.W_regularizer,\n",
        "            'u_regularizer' : self.u_regularizer,\n",
        "            'b_regularizer' : self.b_regularizer,\n",
        "            'W_constraint' : self.W_constraint,\n",
        "            'u_constraint' : self.u_constraint,\n",
        "            'b_constraint' : self.b_constraint\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        print('len of input shape',input_shape)\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight(shape=(input_shape[-1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "\n",
        "        self.u = self.add_weight(shape=(input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_u'.format(self.name),\n",
        "                                 regularizer=self.u_regularizer,\n",
        "                                 constraint=self.u_constraint)\n",
        "\n",
        "        super(AttentionWithContext, self).build(input_shape)\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        # do not pass the mask to the next layers\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        uit = dot_product(x, self.W)\n",
        "\n",
        "        if self.bias:\n",
        "            uit += self.b\n",
        "\n",
        "        uit = K.tanh(uit)\n",
        "        ait = dot_product(uit, self.u)\n",
        "\n",
        "        a = K.exp(ait)\n",
        "\n",
        "        if mask is not None:\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], input_shape[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwiLADGV6Kkv",
        "outputId": "0d9a86a5-8967-4bfb-dee2-d7d1c130c6a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "Number of devices: 1\n"
          ]
        }
      ],
      "source": [
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrfHO1p2BnaF",
        "outputId": "29672932-1ca9-44f9-bdec-f676517408ae"
      },
      "outputs": [
        {
          "ename": "NotFoundError",
          "evalue": "NewRandomAccessFile failed to Create/Open: semantic_seg/model/uncased_L-12_H-768_A-12\\bert_config.json : The system cannot find the file specified.\r\n; No such file or directory",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-27-4ad17bcb6fcb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbert_config_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mbc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStockBertConfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_json_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mbert_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap_stock_config_to_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mbert_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madapter_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    115\u001b[0m       \u001b[0mstring\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstring\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mregular\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \"\"\"\n\u001b[1;32m--> 117\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_preread_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m       \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36m_preread_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     77\u001b[0m         raise errors.PermissionDeniedError(None, None,\n\u001b[0;32m     78\u001b[0m                                            \"File isn't open for reading\")\n\u001b[1;32m---> 79\u001b[1;33m       self._read_buf = _pywrap_file_io.BufferedInputStream(\n\u001b[0m\u001b[0;32m     80\u001b[0m           compat.path_to_str(self.__name), 1024 * 512)\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNotFoundError\u001b[0m: NewRandomAccessFile failed to Create/Open: semantic_seg/model/uncased_L-12_H-768_A-12\\bert_config.json : The system cannot find the file specified.\r\n; No such file or directory"
          ]
        }
      ],
      "source": [
        "def printpls(x, str):\n",
        "    print(str, x)\n",
        "\n",
        "with strategy.scope():  \n",
        "  seq_len = data.max_seq_len\n",
        "  inp_seq_len = data.inp_seq_len\n",
        "  cls_rem_inp_len = data.inp_seq_len - 1\n",
        "  cls_rem_seq_len = data.max_seq_len - 1\n",
        "  sent_len = data.max_sent_len\n",
        "  # sent_len = 5\n",
        "  bert_dim = 768\n",
        "\n",
        "  with tf.io.gfile.GFile(bert_config_file, \"r\") as reader:\n",
        "    bc = StockBertConfig.from_json_string(reader.read())\n",
        "    bert_params = map_stock_config_to_params(bc)\n",
        "    bert_params.adapter_size = None\n",
        "    bert = BertModelLayer.from_params(bert_params, name=\"bert\")\n",
        "\n",
        "  input_ids = keras.layers.Input(shape=(inp_seq_len, ), dtype='int32', name=\"input_ids\")\n",
        "  printpls(input_ids, 'input_ids')\n",
        "\n",
        "  bert_output = bert(input_ids)\n",
        "  printpls(bert_output, 'bert_output')\n",
        "\n",
        "  cls_out = keras.layers.Lambda(lambda seq: seq[:,1:,:])(bert_output)\n",
        "  printpls(cls_out, 'cls_out')\n",
        "\n",
        "  cls_out = keras.layers.Dropout(0.5)(cls_out)\n",
        "  printpls(cls_out, 'cls_out')\n",
        "\n",
        "  lstm_out = Bidirectional(GRU(768, return_sequences=True,input_shape=(cls_rem_inp_len, bert_dim)))(cls_out)\n",
        "  printpls(lstm_out, 'lstm_out')\n",
        "\n",
        "  lstm_att = AttentionWithContext()(lstm_out)\n",
        "  printpls(lstm_att, 'lstm_att')\n",
        "\n",
        "  input_context_left_ids = keras.layers.Input(shape=(sent_len,seq_len,), dtype='int32', name=\"input_context_left_ids\")\n",
        "  printpls(input_context_left_ids, 'input_context_left_ids')\n",
        "\n",
        "  context_encoder_left = keras.layers.TimeDistributed(bert)(input_context_left_ids)\n",
        "  printpls(context_encoder_left, 'context_encoder_left')\n",
        "\n",
        "  context_encoder_cls_out_left =  keras.layers.TimeDistributed(keras.layers.Lambda(lambda seq: seq[:,1:,:]))(context_encoder_left)\n",
        "  printpls(context_encoder_cls_out_left, 'context_encoder_cls_out_left')\n",
        "\n",
        "  lstm_sent_left = keras.layers.TimeDistributed(keras.layers.Bidirectional(GRU(bert_dim, return_sequences=True)))(context_encoder_cls_out_left)\n",
        "  printpls(lstm_sent_left, 'lstm_sent_left')\n",
        "\n",
        "  lstm_att_sent_left = keras.layers.TimeDistributed(AttentionWithContext())(lstm_sent_left)\n",
        "  printpls(lstm_att_sent_left, 'lstm_att_sent_left')\n",
        "\n",
        "  lstm_doc_left = keras.layers.Bidirectional(GRU(bert_dim, return_sequences=True))(lstm_att_sent_left)\n",
        "  printpls(lstm_doc_left, 'lstm_doc_left')\n",
        "\n",
        "  lstm_att_doc_left = AttentionWithContext()(lstm_doc_left)\n",
        "  printpls(lstm_att_doc_left, 'lstm_att_doc_left')\n",
        "\n",
        "  input_context_right_ids = keras.layers.Input(shape=(sent_len,seq_len,), dtype='int32', name=\"input_context_right_ids\")\n",
        "  printpls(input_context_right_ids, 'input_context_right_ids')\n",
        "\n",
        "  context_encoder_right = keras.layers.TimeDistributed(bert)(input_context_right_ids)\n",
        "  printpls(context_encoder_right, 'context_encoder_right')\n",
        "\n",
        "  context_encoder_cls_out_right =  keras.layers.TimeDistributed(keras.layers.Lambda(lambda seq: seq[:,1:,:]))(context_encoder_right)\n",
        "  printpls(context_encoder_cls_out_right, 'context_encoder_cls_out_right')\n",
        "\n",
        "  lstm_sent_right = keras.layers.TimeDistributed(keras.layers.Bidirectional(GRU(bert_dim, return_sequences=True)))(context_encoder_cls_out_right)\n",
        "  printpls(lstm_sent_right, 'lstm_sent_right')\n",
        "\n",
        "  lstm_att_sent_right = keras.layers.TimeDistributed(AttentionWithContext())(lstm_sent_right)\n",
        "  printpls(lstm_att_sent_right, 'lstm_att_sent_right')\n",
        "\n",
        "  lstm_doc_right = keras.layers.Bidirectional(GRU(bert_dim, return_sequences=True))(lstm_att_sent_right)\n",
        "  printpls(lstm_doc_right, 'lstm_doc_right')\n",
        "\n",
        "  lstm_att_doc_right = AttentionWithContext()(lstm_doc_right)\n",
        "  printpls(lstm_att_doc_right, 'lstm_att_doc_right')\n",
        "\n",
        "  cls_out_concat = keras.layers.Concatenate()([lstm_att_doc_left, lstm_att, lstm_att_doc_right])\n",
        "  printpls(cls_out_concat, 'cls_out_concat')\n",
        "\n",
        "  logits = keras.layers.Dense(units=3072,activation=\"tanh\")(cls_out_concat)\n",
        "  printpls(logits, 'logits')\n",
        "\n",
        "  logits = keras.layers.Dropout(0.5)(logits)\n",
        "  printpls(logits, 'logits')\n",
        "\n",
        "  logits = keras.layers.Dense(units=len(classes), activation=\"softmax\")(logits)\n",
        "  printpls(logits, 'logits')\n",
        "\n",
        "  # cls_out_concat = lstm_att_doc\n",
        "  # printpls(cls_out_concat, 'cls_out_concat')\n",
        "\n",
        "  # logits = keras.layers.Dense(units=1536,activation=\"tanh\")(cls_out_concat)\n",
        "  # printpls(logits, 'logits')\n",
        "\n",
        "  # logits = keras.layers.Dropout(0.5)(logits)\n",
        "  # printpls(logits, 'logits')\n",
        "\n",
        "  # logits = keras.layers.Dense(units=len(classes), activation=\"softmax\")(logits)\n",
        "  # printpls(logits, 'logits')\n",
        "\n",
        "  model = keras.Model(inputs=[input_ids, input_context_left_ids, input_context_right_ids], outputs=logits)\n",
        "\n",
        "  load_stock_weights(bert, bert_ckpt_file)\n",
        "\n",
        "  model.compile(\n",
        "  optimizer=keras.optimizers.Adam(1e-5),\n",
        "  loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "  metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")]\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mt0GswquBPhH",
        "outputId": "18a200b5-bccc-4bad-e11a-07dc42bd7c61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_context_ids (InputLayer)  [(None, 193, 308)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_ids (InputLayer)          [(None, 308)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_4 (TimeDistrib (None, 193, 308, 768 108890112   input_context_ids[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "bert (BertModelLayer)           (None, 308, 768)     108890112   input_ids[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_5 (TimeDistrib (None, 193, 307, 768 0           time_distributed_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 307, 768)     0           bert[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_6 (TimeDistrib (None, 193, 307, 153 7087104     time_distributed_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 307, 768)     0           lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_7 (TimeDistrib (None, 193, 1536)    2362368     time_distributed_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) (None, 307, 1536)    7087104     dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_5 (Bidirectional) (None, 193, 1536)    10626048    time_distributed_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "attention_with_context_3 (Atten (None, 1536)         2362368     bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "attention_with_context_5 (Atten (None, 1536)         2362368     bidirectional_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3072)         0           attention_with_context_3[0][0]   \n",
            "                                                                 attention_with_context_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 3072)         9440256     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 3072)         0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 10)           30730       dropout_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 150,248,458\n",
            "Trainable params: 150,248,458\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "9fpJvjEyFpKf"
      },
      "outputs": [],
      "source": [
        "from packaging import version\n",
        "############## path check \n",
        "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "60LUINrlFkhb"
      },
      "outputs": [],
      "source": [
        "#print(tensorboard.__version__)\n",
        "\n",
        "############## ADD save model path \n",
        "my_callbacks = [EarlyStopping(patience=2, monitor=\"val_loss\"),  ModelCheckpoint(filepath='model_{epoch:02d}.hdf5', save_best_only=True, save_weights_only = False, monitor='val_loss', mode='auto',save_freq = 'epoch'),keras.callbacks.TensorBoard(log_dir=logdir)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGUYggDGFrnX",
        "outputId": "9a609512-8433-4a32-8769-143557ef4ac8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer AttentionWithContext has arguments in `__init__` and therefore must override `get_config`.\n",
            "C:\\Users\\e_sai\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  warnings.warn('Custom mask layers require a config and must override '\n",
            "Epoch 1/10\n"
          ]
        }
      ],
      "source": [
        "train_flag = 1\n",
        "\n",
        "if train_flag:\n",
        "  history = model.fit(\n",
        "    x=[data.train_x, data.train_x_left_context, data.train_x_right_context], \n",
        "    y= data.train_y,\n",
        "    validation_split=0.1,\n",
        "    batch_size=1,\n",
        "    shuffle=True,\n",
        "    epochs = 5,\n",
        "    callbacks = my_callbacks\n",
        "  )\n",
        "\n",
        "else:\n",
        "  model = tf.keras.models.load_model('./model_03.hdf5', custom_objects={\"BertModelLayer\": BertModelLayer, \"keras\":tf.keras, \"AttentionWithContext\": AttentionWithContext})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzfTfiK1FvAe"
      },
      "outputs": [],
      "source": [
        "_, train_acc = model.evaluate([data.train_x,data.train_x_context], data.train_y)\n",
        "_, test_acc = model.evaluate([data.test_x,data.test_x_context], data.test_y)\n",
        "\n",
        "print(\"train acc\", train_acc)\n",
        "print(\"test acc\", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P835Sd_aF545"
      },
      "outputs": [],
      "source": [
        "train_pred = model.predict([data.train_x, data.train_x_left_context, data.train_x_right_context])\n",
        "test_pred = model.predict([data.test_x, data.test_x_left_context, data.test_x_right_context])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dW4AMp85WU2"
      },
      "outputs": [],
      "source": [
        "print(classification_report(data.test_y, y_pred, target_names=classes))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "model_full_context_distributed.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "37b255bb5dc0d995b91bd1b934b878e610a26475f52eafaf29fdb395fb105534"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
